{"metadata":{"title":"European Commission AI Act Guidelines","source":"https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai","lastUpdated":"2026-01-12"},"guidelines":[{"title":"Guidelines on Prohibited AI Practices","articleReference":"Article 5","publishedDate":"2025-02-04","status":"published","summary":"Official interpretation of the 8 prohibited AI practices including manipulation, exploitation of vulnerabilities, social scoring, criminal risk assessment, facial recognition scraping, emotion recognition, biometric categorisation, and real-time remote biometric identification.","keyPoints":["Clarifies scope of subliminal techniques","Defines significant harm threshold","Explains vulnerability exploitation criteria","Details social scoring prohibition scope","Specifies law enforcement exceptions"]},{"title":"Guidelines on AI System Definition","articleReference":"Article 3(1)","publishedDate":"2025-02-06","status":"published","summary":"Clarifies what constitutes an AI system under the regulation, distinguishing from traditional software.","keyPoints":["Machine-based system criteria","Autonomy levels explained","Adaptiveness after deployment","Inference from input requirement","Output types covered"]},{"title":"Guidelines on GPAI Provider Obligations","articleReference":"Articles 51-56","status":"published","summary":"Scope and requirements for general-purpose AI model providers.","keyPoints":["Technical documentation requirements","Training data transparency","Downstream provider information","Systemic risk assessment","Open source exceptions"]},{"title":"Guidelines on Transparent AI Systems","articleReference":"Article 50","expectedDate":"2026-Q2","status":"pending","summary":"Expected guidance on transparency obligations for AI-human interaction, emotion recognition, biometric categorisation, and deep fakes."},{"title":"Guidelines on High-Risk Classification","articleReference":"Article 6","expectedDate":"2026-02-02","status":"pending","summary":"Expected guidance on determining when AI systems qualify as high-risk."}],"codesOfPractice":[{"title":"GPAI Code of Practice","status":"draft","chapters":[{"chapter":1,"title":"Transparency","focus":"Documentation and information sharing"},{"chapter":2,"title":"Copyright","focus":"Training data and intellectual property"},{"chapter":3,"title":"Safety and Security","focus":"Risk management and cybersecurity"}],"drafts":[{"version":"First draft","date":"2024-11"},{"version":"Second draft","date":"2025-01"},{"version":"Third draft","date":"2025-03"}]},{"title":"Code of Practice on AI-Generated Content Marking","status":"draft","expectedFinal":"2026-Q2","focus":"Watermarking, metadata, and labelling of synthetic content"}]}