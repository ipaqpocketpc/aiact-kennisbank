{"metadata":{"title":"EU AI Act - Veelgestelde Vragen (FAQ)","language":"nl","lastUpdated":"2026-01-12"},"categories":[{"category":"Algemeen","questions":[{"question":"Wat is de EU AI Act?","answer":"De EU AI Act (Verordening (EU) 2024/1689) is de eerste uitgebreide wetgeving ter wereld die kunstmatige intelligentie reguleert. Het is een EU-verordening die direct van toepassing is in alle lidstaten en een risicogebaseerde aanpak hanteert voor AI-systemen."},{"question":"Wanneer treedt de AI Act in werking?","answer":"De AI Act is gefaseerd van kracht:\n- 2 februari 2025: Verboden praktijken + AI-geletterdheid\n- 2 augustus 2025: GPAI-verplichtingen\n- 2 augustus 2026: Hoog-risico verplichtingen + transparantie\n- 2 augustus 2027: Volledige toepassing"},{"question":"Voor wie geldt de AI Act?","answer":"De AI Act geldt voor:\n- Providers (ontwikkelaars) van AI-systemen\n- Deployers (gebruikers) van AI-systemen\n- Importeurs en distributeurs\n- Fabrikanten van producten met AI\n\nDit geldt ongeacht of ze in de EU gevestigd zijn, zolang het AI-systeem in de EU wordt aangeboden of de output in de EU wordt gebruikt."}]},{"category":"Risicocategorieen","questions":[{"question":"Welke AI-systemen zijn verboden?","answer":"Verboden sinds 2 februari 2025:\n1. AI voor subliminale manipulatie\n2. AI die kwetsbaarheden uitbuit\n3. Social scoring door overheden\n4. Predictive policing op basis van profiling alleen\n5. Ongericht scrapen van gezichtsbeelden\n6. Emotieherkenning op werk/school\n7. Biometrische categorisatie op gevoelige kenmerken\n8. Real-time biometrische identificatie (met uitzonderingen)"},{"question":"Wat zijn hoog-risico AI-systemen?","answer":"Hoog-risico systemen vallen onder twee categorieen:\n\n1. AI in producten (Annex I): medische apparaten, machines, speelgoed, voertuigen, etc.\n\n2. Standalone AI (Annex III): biometrie, kritieke infrastructuur, onderwijs, werkgelegenheid, essentiele diensten, rechtshandhaving, migratie, rechtspraak."},{"question":"Wat zijn de verplichtingen voor hoog-risico AI?","answer":"Providers moeten:\n- Risicomanagementsysteem implementeren\n- Data governance waarborgen\n- Technische documentatie opstellen\n- Automatische logging inbouwen\n- Transparante gebruiksaanwijzingen maken\n- Menselijk toezicht mogelijk maken\n- Nauwkeurigheid en robuustheid garanderen\n- Conformiteitsbeoordeling uitvoeren\n- Registreren in EU-database"}]},{"category":"Compliance","questions":[{"question":"Wat is AI-geletterdheid en is het verplicht?","answer":"Ja, AI-geletterdheid is verplicht sinds 2 februari 2025 (Artikel 4). Organisaties moeten ervoor zorgen dat personeel dat met AI-systemen werkt voldoende kennis heeft van:\n- Technische aspecten van AI\n- Mogelijkheden en beperkingen\n- Ethische overwegingen\n- Relevante regelgeving"},{"question":"Moet ik mijn AI-systeem registreren?","answer":"Ja, als het een hoog-risico systeem is uit Annex III (behalve kritieke infrastructuur). Registratie moet voor het op de markt brengen in de EU-database. Deployers die overheidsinstanties zijn moeten ook registreren."},{"question":"Heb ik een conformiteitsbeoordeling nodig?","answer":"Voor hoog-risico AI-systemen is conformiteitsbeoordeling verplicht:\n\n- Annex III punt 1 (biometrie): mogelijk derde partij nodig\n- Annex III punten 2-8: interne controle volstaat\n- Annex I producten: volg sectorale wetgeving\n\nNa succesvolle beoordeling: CE-markering aanbrengen."}]},{"category":"Boetes en Handhaving","questions":[{"question":"Wat zijn de boetes bij niet-naleving?","answer":"Maximale boetes:\n- Verboden praktijken: EUR 35 miljoen of 7% wereldwijde omzet\n- Hoog-risico verplichtingen: EUR 15 miljoen of 3% omzet\n- Onjuiste informatie: EUR 7,5 miljoen of 1% omzet\n\nVoor MKB en startups gelden lagere maxima."},{"question":"Wie handhaaft de AI Act?","answer":"Handhaving gebeurt op twee niveaus:\n\n1. Nationaal: Markttoezichtautoriteiten per lidstaat (in NL: AP als coordinator)\n\n2. EU: AI Office voor GPAI-modellen en coordinatie\n\nBurgers kunnen klachten indienen bij nationale autoriteiten."}]},{"category":"GPAI en Foundation Models","questions":[{"question":"Wat is een general-purpose AI model?","answer":"Een GPAI-model is een AI-model dat:\n- Getraind is met grote hoeveelheden data\n- Significante algemeenheid toont\n- Breed inzetbaar is voor diverse taken\n- Geintegreerd kan worden in downstream systemen\n\nVoorbeelden: GPT-4, Claude, Gemini, Llama."},{"question":"Wat zijn de verplichtingen voor GPAI?","answer":"GPAI-providers moeten (vanaf augustus 2025):\n- Technische documentatie opstellen\n- Informatie aan downstream providers geven\n- Auteursrechtbeleid naleven\n- Publieke samenvatting van trainingsdata publiceren\n\nBij systemisch risico (>10^25 FLOPS): extra verplichtingen."}]},{"category":"Praktisch","questions":[{"question":"Waar begin ik met AI Act compliance?","answer":"Stappenplan:\n1. Inventariseer alle AI-systemen in gebruik/ontwikkeling\n2. Classificeer per risicocategorie\n3. Stop verboden praktijken direct\n4. Start met AI-geletterdheid training\n5. Plan compliance-acties per deadline\n6. Documenteer beslissingen en maatregelen"},{"question":"Zijn open source AI-modellen uitgezonderd?","answer":"Gedeeltelijk. Open source modellen hebben minder verplichtingen TENZIJ:\n- Het een hoog-risico systeem is\n- Het onder verboden praktijken valt\n- Het transparantieverplichtingen triggert (deepfakes, emotieherkenning)\n- Het systemisch risico vormt (>10^25 FLOPS)"}]}]}